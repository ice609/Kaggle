{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 采用Transfer Learning,对VGG16进行特征抽取\n",
    "# 即对VGG16中Flatten后面的神经层全部去掉，换上我们自己的神经层，这个行为叫做特征抽取\n",
    "# 注：VGG16中，前面的多重卷积层和池化层对图像特征已做了很好的提取，此部分可以直接使用\n",
    "\n",
    "# 通过代码来初始化一个VGG16网络实例\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# 下载vgg16模型预训练权重，将之放到~/.keras/model/下面，\n",
    "# 这样在keras导入vgg16的时候就不会联网下载\n",
    "\n",
    "# weight参数告诉程序将网络的卷积层和max pooling层对应的参数传递过来，\n",
    "# 并将它们初始化成对应的网络层次\n",
    "# include_top表示是否也要把Flatten()后面的网络层也下载过来\n",
    "# input_shape告诉网络，我们输入图片的大小是150*150像素，每个像素由[R, G, B]三个值表示\n",
    "conv_base = VGG16(weights=\"imagenet\", include_top=False,input_shape = (150,150,3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n",
      "Found 24 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 接下来我们将把自己的图片读进来，\n",
    "# 把图片喂给上面网络，让它把图片的隐含信息给抽取出来\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \"C:/Users/hh/Desktop/Kaggle/2.0 CatdogNet/input/TE_Pd_train\"\n",
    "train_dir = os.path.join(base_dir,\"train\")\n",
    "validation_dir = os.path.join(base_dir,\"validation\")\n",
    "test_dir = os.path.join(base_dir,\"test\")\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "batch_size = 9\n",
    "\n",
    "# generator 实际上是将数据批量读入内存，使得代码能以for in 的方式去方便的访问\n",
    "# 利用VGG16的卷积层把图片的特征抽取出来\n",
    "def extract_features(directory,sample_count):\n",
    "    features = np.zeros(shape = (sample_count,4,4,512))\n",
    "    labels = np.zeros(shape = (sample_count))\n",
    "    generator = datagen.flow_from_directory(directory,target_size = (150,150),\n",
    "                                           batch_size = batch_size,\n",
    "                                           class_mode = \"binary\")\n",
    "    i = 0\n",
    "    for inputs_batch,labels_batch in generator:\n",
    "        # 把图片输入VGG16层的卷积层，让它把图片信息抽取出来\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        # feature_batch是4*4*512结构的\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # for in 在generator上的循环是无限的，因此需要主动break掉\n",
    "            break\n",
    "        return features,labels\n",
    "# extract_features返回数据格式为（samples，4,4,512）\n",
    "train_features,train_labels = extract_features(train_dir,36)\n",
    "validation_features,validation_labels = extract_features(validation_dir,12)\n",
    "test_features,test_labels = extract_features(test_dir,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 13ms/step - loss: 0.7094 - acc: 0.6667 - val_loss: 0.6812 - val_acc: 0.8333\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6612 - acc: 0.9722 - val_loss: 0.6319 - val_acc: 0.8333\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6499 - acc: 0.9722 - val_loss: 0.5879 - val_acc: 0.8333\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6074 - acc: 0.9722 - val_loss: 0.5549 - val_acc: 0.9167\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6195 - acc: 0.9722 - val_loss: 0.5223 - val_acc: 0.9167\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.6439 - acc: 0.9167 - val_loss: 0.4963 - val_acc: 0.9167\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5882 - acc: 1.0000 - val_loss: 0.4721 - val_acc: 0.9167\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5838 - acc: 1.0000 - val_loss: 0.4540 - val_acc: 0.9167\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5667 - acc: 1.0000 - val_loss: 0.4407 - val_acc: 0.9167\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5714 - acc: 0.9722 - val_loss: 0.4214 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5640 - acc: 1.0000 - val_loss: 0.4080 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5668 - acc: 1.0000 - val_loss: 0.3959 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5780 - acc: 0.9722 - val_loss: 0.3801 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5551 - acc: 1.0000 - val_loss: 0.3695 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5488 - acc: 1.0000 - val_loss: 0.3632 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5435 - acc: 1.0000 - val_loss: 0.3525 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5542 - acc: 1.0000 - val_loss: 0.3446 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5368 - acc: 1.0000 - val_loss: 0.3383 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5405 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 1.0000 - val_loss: 0.3197 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5316 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5354 - acc: 1.0000 - val_loss: 0.3069 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5374 - acc: 1.0000 - val_loss: 0.3126 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5268 - acc: 1.0000 - val_loss: 0.3027 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5288 - acc: 1.0000 - val_loss: 0.2972 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5296 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5301 - acc: 1.0000 - val_loss: 0.2928 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5276 - acc: 1.0000 - val_loss: 0.2851 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5266 - acc: 1.0000 - val_loss: 0.2817 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5238 - acc: 1.0000 - val_loss: 0.2787 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5219 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5226 - acc: 1.0000 - val_loss: 0.2679 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5216 - acc: 1.0000 - val_loss: 0.2639 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5227 - acc: 1.0000 - val_loss: 0.2597 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5204 - acc: 1.0000 - val_loss: 0.2508 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5320 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5190 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5185 - acc: 1.0000 - val_loss: 0.2416 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5192 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5184 - acc: 1.0000 - val_loss: 0.2375 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5173 - acc: 1.0000 - val_loss: 0.2371 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5174 - acc: 1.0000 - val_loss: 0.2360 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5201 - acc: 1.0000 - val_loss: 0.2278 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5175 - acc: 1.0000 - val_loss: 0.2272 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5167 - acc: 1.0000 - val_loss: 0.2231 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5180 - acc: 1.0000 - val_loss: 0.2202 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5163 - acc: 1.0000 - val_loss: 0.2186 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5154 - acc: 1.0000 - val_loss: 0.2157 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5158 - acc: 1.0000 - val_loss: 0.2137 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5158 - acc: 1.0000 - val_loss: 0.2117 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5153 - acc: 1.0000 - val_loss: 0.2089 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5157 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5154 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5162 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5141 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5140 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5139 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5134 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 1.0000 - val_loss: 0.1985 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5135 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5137 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5134 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5127 - acc: 1.0000 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5125 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5123 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5124 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5122 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5123 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5120 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5122 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5115 - acc: 1.0000 - val_loss: 0.1901 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5110 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5112 - acc: 1.0000 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5105 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5112 - acc: 1.0000 - val_loss: 0.1851 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5107 - acc: 1.0000 - val_loss: 0.1857 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5105 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5106 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5101 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5103 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5099 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5102 - acc: 1.0000 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5096 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5103 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5096 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5093 - acc: 1.0000 - val_loss: 0.1835 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5092 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5090 - acc: 1.0000 - val_loss: 0.1795 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5087 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5088 - acc: 1.0000 - val_loss: 0.1779 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5085 - acc: 1.0000 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5086 - acc: 1.0000 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5085 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5080 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5082 - acc: 1.0000 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5082 - acc: 1.0000 - val_loss: 0.1746 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5076 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5079 - acc: 1.0000 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5080 - acc: 1.0000 - val_loss: 0.1757 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5073 - acc: 1.0000 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5072 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5074 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5071 - acc: 1.0000 - val_loss: 0.1749 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5067 - acc: 1.0000 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5070 - acc: 1.0000 - val_loss: 0.1743 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5070 - acc: 1.0000 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5065 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5063 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5060 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5058 - acc: 1.0000 - val_loss: 0.1739 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5056 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5053 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5053 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5056 - acc: 1.0000 - val_loss: 0.1726 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5053 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5050 - acc: 1.0000 - val_loss: 0.1735 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5049 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5047 - acc: 1.0000 - val_loss: 0.1728 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5044 - acc: 1.0000 - val_loss: 0.1733 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.5038 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5047 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5041 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5039 - acc: 1.0000 - val_loss: 0.1717 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5042 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5039 - acc: 1.0000 - val_loss: 0.1715 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5039 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5040 - acc: 1.0000 - val_loss: 0.1710 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5033 - acc: 1.0000 - val_loss: 0.1708 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5037 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5027 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5025 - acc: 1.0000 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5028 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5025 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5030 - acc: 1.0000 - val_loss: 0.1699 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5024 - acc: 1.0000 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5024 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5022 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5022 - acc: 1.0000 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5019 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5024 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5016 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5017 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5016 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5017 - acc: 1.0000 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5009 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5009 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5001 - acc: 1.0000 - val_loss: 0.1696 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5006 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5002 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5001 - acc: 1.0000 - val_loss: 0.1688 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5004 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5009 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4997 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5000 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.5002 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4989 - acc: 1.0000 - val_loss: 0.1683 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4995 - acc: 1.0000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4999 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4994 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4991 - acc: 1.0000 - val_loss: 0.1681 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4990 - acc: 1.0000 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4984 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4973 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4977 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4975 - acc: 1.0000 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4988 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4976 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4985 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4978 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4964 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4974 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4969 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4955 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4978 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4969 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4965 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4967 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4958 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4958 - acc: 1.0000 - val_loss: 0.1664 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4953 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4957 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4958 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4951 - acc: 1.0000 - val_loss: 0.1662 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4958 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 3ms/step - loss: 0.4948 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4947 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4950 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4947 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4938 - acc: 1.0000 - val_loss: 0.1659 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4938 - acc: 1.0000 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4946 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4931 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4927 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4926 - acc: 1.0000 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4941 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4929 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4934 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4926 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 2ms/step - loss: 0.4928 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 上面代码利用VGG16的卷积层把图片的特征抽取出来，\n",
    "# 接下来就可以把抽取的特征输入到我们自己的神经层中进行分类\n",
    "train_features = np.reshape(train_features,(36,4*4*512))\n",
    "validation_features = np.reshape(validation_features,(12,4*4*512))\n",
    "test_features = np.reshape(test_features,(12,4*4*512))\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "# 构造新的网络对输出层进行分类\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256,activation = \"relu\",input_dim = 4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation = \"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 2e-5), loss = \"binary_crossentropy\",\n",
    "             metrics = [\"acc\"])\n",
    "history = model.fit(train_features,train_labels,epochs = 200,batch_size = 12,\n",
    "                   validation_data = (validation_features,validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23546be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9MYYE+Ms0BtjTIyzQG+MMTHu/wFp5FPmXzYf3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecc9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制曲线\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history[\"acc\"]\n",
    "val_acc = history.history[\"val_acc\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs = range(1,len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs,acc,\"bo\",label = \"Train_acc\")\n",
    "plt.plot(epochs,val_acc,\"b\",label = \"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,loss,\"bo\",label = \"Training loss\")\n",
    "plt.plot(epochs,val_loss,\"b\",label= \"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
